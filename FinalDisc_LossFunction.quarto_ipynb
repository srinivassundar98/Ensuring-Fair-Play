{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Discrimination Loss Fn\n",
        "jupyter: python3\n",
        "---"
      ],
      "id": "fc911e5e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import joblib\n",
        "import re\n",
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "import numpy as np\n",
        "\n",
        "# Datasets\n",
        "from aif360.datasets import MEPSDataset19\n",
        "# Fairness metrics\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "\n",
        "# Explainers\n",
        "from aif360.explainers import MetricTextExplainer\n",
        "\n",
        "# Scalers\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "id": "6796a1a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_orig_panel19_train = MEPSDataset19()"
      ],
      "id": "fd6ff4d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sens_ind = 0\n",
        "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
        "unprivileged_groups = [{sens_attr: v} for v in\n",
        "                    dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
        "privileged_groups = [{sens_attr: v} for v in\n",
        "                    dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
      ],
      "id": "73a0d8e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_orig_panel19_train.feature_names[1]"
      ],
      "id": "6d263452",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare data\n",
        "X = dataset_orig_panel19_train.features\n",
        "y = dataset_orig_panel19_train.labels.ravel()\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train\n",
        "X_test_scaled = X_test\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict probabilities on the same scaled training data\n",
        "train_probabilities = model.predict_proba(X_train_scaled)[:, 1]\n",
        "\n",
        "# Calculation of discrimination index without modifying dataset structure\n",
        "sens_attr_index = dataset_orig_panel19_train.feature_names.index('RACE')\n",
        "\n",
        "\n",
        "\n",
        "# Define unprivileged and privileged values\n",
        "unprivileged_val = 0.0\n",
        "privileged_val = 1.0"
      ],
      "id": "0554a335",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the model\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Custom loss function\n",
        "def discrimination_loss(output, target, sensitive_features, lambda_val=10, k=2):\n",
        "    criterion = nn.BCELoss()\n",
        "    standard_loss = criterion(output, target)\n",
        "    mask_unpriv = (sensitive_features == 0)\n",
        "    mask_priv = (sensitive_features == 1)\n",
        "    prob_unpriv = torch.mean(output[mask_unpriv])\n",
        "    prob_priv = torch.mean(output[mask_priv])\n",
        "\n",
        "    discrimination = lambda_val * (prob_priv - prob_unpriv) ** k\n",
        "\n",
        "    loss_val=(1 + lambda_val * discrimination) * standard_loss\n",
        "    return loss_val,discrimination.item() \n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    predicted_classes = (predictions >= 0.5).float()\n",
        "    return (predicted_classes == targets).float().mean()\n",
        "\n",
        "\n",
        "data = torch.tensor(X_train_scaled).float()\n",
        "targets = torch.tensor(y_train).float().unsqueeze(1)\n",
        "\n",
        "# Correctly preparing the sensitive features\n",
        "threshold = 0.5  # Adjust the threshold according to your specific case\n",
        "sensitive_features = torch.tensor((data[:, 1].numpy() > threshold).astype(float)).float()\n",
        "features = torch.cat((data[:, :1], data[:, 2:]), dim=1)\n",
        "\n",
        "# Assuming similar preparation for test data\n",
        "test_data = torch.tensor(X_test_scaled).float()\n",
        "test_targets = torch.tensor(y_test).float().unsqueeze(1)\n",
        "test_sensitive_features = torch.tensor((test_data[:, 1].numpy() > threshold).astype(float)).float()\n",
        "test_features = torch.cat((test_data[:, :1], test_data[:, 2:]), dim=1)\n",
        "\n",
        "model2 = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model2.parameters(), lr=0.01)\n",
        "train_losses, train_accuracies, train_discriminations,train_fairness = [], [], [],[]\n",
        "test_losses, test_accuracies, test_discriminations,test_fairness = [], [], [],[]\n",
        "\n",
        "# Training loop\n",
        "model2.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model2(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model2.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model2(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses.append(loss.item())\n",
        "    train_accuracies.append(train_accuracy.item() * 100)\n",
        "    train_discriminations.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness.append(fairness)\n",
        "    test_fairness.append(fairness)\n",
        "    test_losses.append(test_loss.item())\n",
        "    test_accuracies.append(test_accuracy.item() * 100)\n",
        "    test_discriminations.append(test_discrimination)\n",
        "    model2.train()"
      ],
      "id": "5c78850e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MODEL ACCROSS DIFFERENT VALUES OF LAMBDA\n",
        "\n",
        "#### LAMBDA < 1\n"
      ],
      "id": "aa9dcaf0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model3 = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model3.parameters(), lr=0.01)\n",
        "train_losses3, train_accuracies3, train_discriminations3,train_fairness3 = [], [], [],[]\n",
        "test_losses3, test_accuracies3, test_discriminations3,test_fairness3 = [], [], [],[]\n",
        "\n",
        "# Training loop\n",
        "model3.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model3(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features, lambda_val=0.01, k=2)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model3.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model3(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features, lambda_val=0.01, k=2)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses3.append(loss.item())\n",
        "    train_accuracies3.append(train_accuracy.item() * 100)\n",
        "    train_discriminations3.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness3.append(fairness)\n",
        "    test_fairness3.append(fairness)\n",
        "    test_losses3.append(test_loss.item())\n",
        "    test_accuracies3.append(test_accuracy.item() * 100)\n",
        "    test_discriminations3.append(test_discrimination)\n",
        "    model3.train()"
      ],
      "id": "51518f13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LAMBDA = 1\n"
      ],
      "id": "5127fc95"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model4 = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model4.parameters(), lr=0.01)\n",
        "train_losses4, train_accuracies4, train_discriminations4,train_fairness4 = [], [], [],[]\n",
        "test_losses4, test_accuracies4, test_discriminations4,test_fairness4 = [], [], [],[]\n",
        "\n",
        "# Training loop\n",
        "model4.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model4(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features, lambda_val=1, k=2)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model4.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model4(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features, lambda_val=1, k=2)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses4.append(loss.item())\n",
        "    train_accuracies4.append(train_accuracy.item() * 100)\n",
        "    train_discriminations4.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness4.append(fairness)\n",
        "    test_fairness4.append(fairness)\n",
        "    test_losses4.append(test_loss.item())\n",
        "    test_accuracies4.append(test_accuracy.item() * 100)\n",
        "    test_discriminations4.append(test_discrimination)\n",
        "    model4.train()"
      ],
      "id": "674b3c3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LAMBDA > 1\n"
      ],
      "id": "cf612087"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model5 = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model5.parameters(), lr=0.01)\n",
        "train_losses5, train_accuracies5, train_discriminations5,train_fairness5 = [], [], [],[]\n",
        "test_losses5, test_accuracies5, test_discriminations5,test_fairness5 = [], [], [],[]\n",
        "\n",
        "# Training loop\n",
        "model5.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model5(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features, lambda_val=10, k=2)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model5.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model5(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features, lambda_val=10, k=2)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses5.append(loss.item())\n",
        "    train_accuracies5.append(train_accuracy.item() * 100)\n",
        "    train_discriminations5.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness5.append(fairness)\n",
        "    test_fairness5.append(fairness)\n",
        "    test_losses5.append(test_loss.item())\n",
        "    test_accuracies5.append(test_accuracy.item() * 100)\n",
        "    test_discriminations5.append(test_discrimination)\n",
        "    model5.train()"
      ],
      "id": "43a2ce49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LAMBDA >> 1\n"
      ],
      "id": "44af732d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model6 = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model6.parameters(), lr=0.01)\n",
        "train_losses6, train_accuracies6, train_discriminations6,train_fairness6 = [], [], [],[]\n",
        "test_losses6, test_accuracies6, test_discriminations6,test_fairness6 = [], [], [],[]\n",
        "\n",
        "# Training loop\n",
        "model6.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model6(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features, lambda_val=100, k=2)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model6.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model6(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features, lambda_val=100, k=2)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses6.append(loss.item())\n",
        "    train_accuracies6.append(train_accuracy.item() * 100)\n",
        "    train_discriminations6.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness6.append(fairness)\n",
        "    test_fairness6.append(fairness)\n",
        "    test_losses6.append(test_loss.item())\n",
        "    test_accuracies6.append(test_accuracy.item() * 100)\n",
        "    test_discriminations6.append(test_discrimination)\n",
        "    model6.train()"
      ],
      "id": "632d3a74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MODEL ACCROSS DIFFERENT VALUES OF K\n",
        "\n",
        "### K=2\n"
      ],
      "id": "ef6328e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model7 = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model7.parameters(), lr=0.01)\n",
        "train_losses7, train_accuracies7, train_discriminations7,train_fairness7 = [], [], [],[]\n",
        "test_losses7, test_accuracies7, test_discriminations7,test_fairness7 = [], [], [],[]\n",
        "\n",
        "# Training loop\n",
        "model7.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model7(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features, lambda_val=100, k=2)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model7.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model7(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features, lambda_val=100, k=2)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses7.append(loss.item())\n",
        "    train_accuracies7.append(train_accuracy.item() * 100)\n",
        "    train_discriminations7.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness7.append(fairness)\n",
        "    test_fairness7.append(fairness)\n",
        "    test_losses7.append(test_loss.item())\n",
        "    test_accuracies7.append(test_accuracy.item() * 100)\n",
        "    test_discriminations7.append(test_discrimination)\n",
        "    model7.train()\n"
      ],
      "id": "e1e905bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K=3\n"
      ],
      "id": "f18be1f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model8 = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model8.parameters(), lr=0.01)\n",
        "train_losses8, train_accuracies8, train_discriminations8,train_fairness8 = [], [], [],[]\n",
        "test_losses8, test_accuracies8, test_discriminations8,test_fairness8 = [], [], [],[]\n",
        "\n",
        "# Training loop\n",
        "model8.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model8(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features, lambda_val=100, k=3)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model8.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model8(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features, lambda_val=100, k=3)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses8.append(loss.item())\n",
        "    train_accuracies8.append(train_accuracy.item() * 100)\n",
        "    train_discriminations8.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness8.append(fairness)\n",
        "    test_fairness8.append(fairness)\n",
        "    test_losses8.append(test_loss.item())\n",
        "    test_accuracies8.append(test_accuracy.item() * 100)\n",
        "    test_discriminations8.append(test_discrimination)\n",
        "    model8.train()\n"
      ],
      "id": "c28a5b7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MODEL ACCROSS DIFFERENT VALUES OF LAMBDA\n"
      ],
      "id": "b43952eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_comp_metric(title, y_label, val1, val2, val3, val4):\n",
        "    epochs = list(range(1, 101))\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Adding Train Line with Markers\n",
        "    if val1:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=epochs, y=val1, mode='lines+markers',\n",
        "            name='Lambda = 0.1',\n",
        "            line=dict(color='RoyalBlue', width=2),\n",
        "            marker=dict(color='RoyalBlue', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "        ))\n",
        "    if val2:\n",
        "\n",
        "        # Adding Test Line with Markers\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=epochs, y=val2, mode='lines+markers',\n",
        "            name='lambda = 1',\n",
        "            line=dict(color='Crimson', width=2, dash='dot'),\n",
        "            marker=dict(color='Crimson', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "        ))\n",
        "    # Adding Test Line with Markers\n",
        "    if val3:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=epochs, y=val3, mode='lines+markers',\n",
        "            name='lambda = 10',\n",
        "            line=dict(color='Pink', width=2, dash='dot'),\n",
        "            marker=dict(color='Pink', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "        ))\n",
        "\n",
        "    if val4:\n",
        "     # Adding Test Line with Markers\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=epochs, y=val4, mode='lines+markers',\n",
        "            name='lambda = 100',\n",
        "            line=dict(color='Purple', width=2, dash='dot'),\n",
        "            marker=dict(color='Purple', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "    ))\n",
        "\n",
        "\n",
        "    # Update Layout\n",
        "    fig.update_layout(\n",
        "        title={'text': title, 'y':0.9, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},\n",
        "        xaxis_title='Epoch',\n",
        "        yaxis_title=y_label,\n",
        "        legend=dict(x=0.1, y=1.1, orientation='h'),\n",
        "        font=dict(family=\"Helvetica, Arial, sans-serif\", size=12, color=\"black\"),\n",
        "        plot_bgcolor='white',\n",
        "        margin=dict(l=40, r=40, t=40, b=30)\n",
        "    )\n",
        "\n",
        "    # Gridlines and Axes styles\n",
        "    fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "    fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "\n",
        "    fig.show()"
      ],
      "id": "c24b1a84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_comp_metric(\"TEST_Fairness\", \"Fairness\", test_fairness3, test_fairness4, test_fairness5, test_fairness6)\n",
        "plot_comp_metric(\"TEST_Discriminations\", \"Discrimination\", test_discriminations3, test_discriminations4, test_discriminations5, test_discriminations6)\n",
        "plot_comp_metric(\"TEST_Losses\", \"Losses\", test_losses3,test_losses4,test_losses5,test_losses6)"
      ],
      "id": "bd9772fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MODEL ACCROSS DIFFERENT VALUES OF K\n"
      ],
      "id": "47e62bb7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_comp_metric_k(title, y_label, val1, val2):\n",
        "    epochs = list(range(1, 101))\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Adding Train Line with Markers\n",
        "    if val1:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=epochs, y=val1, mode='lines+markers',\n",
        "            name='K = 2',\n",
        "            line=dict(color='RoyalBlue', width=2),\n",
        "            marker=dict(color='RoyalBlue', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "        ))\n",
        "    if val2:\n",
        "\n",
        "        # Adding Test Line with Markers\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=epochs, y=val2, mode='lines+markers',\n",
        "            name='K = 3',\n",
        "            line=dict(color='Crimson', width=2, dash='dot'),\n",
        "            marker=dict(color='Crimson', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "        ))\n",
        "\n",
        "\n",
        "\n",
        "    # Update Layout\n",
        "    fig.update_layout(\n",
        "        title={'text': title, 'y':0.9, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},\n",
        "        xaxis_title='Epoch',\n",
        "        yaxis_title=y_label,\n",
        "        legend=dict(x=0.1, y=1.1, orientation='h'),\n",
        "        font=dict(family=\"Helvetica, Arial, sans-serif\", size=12, color=\"black\"),\n",
        "        plot_bgcolor='white',\n",
        "        margin=dict(l=40, r=40, t=40, b=30)\n",
        "    )\n",
        "\n",
        "    # Gridlines and Axes styles\n",
        "    fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "    fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "\n",
        "    fig.show()"
      ],
      "id": "8cd92f9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_comp_metric_k(\"TEST_Fairness\", \"Fairness\", test_fairness7, test_fairness8)\n",
        "plot_comp_metric_k(\"TEST_Discriminations\", \"Discrimination\", test_discriminations7, test_discriminations8)\n",
        "plot_comp_metric_k(\"TEST_Losses\", \"Losses\", test_losses7,test_losses8)"
      ],
      "id": "6385ff65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LOSS ACCURACY AND DISCRIMINATION FOR MODEL WITH DISCRIMINATION FUNCTION\n"
      ],
      "id": "3a9a83bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_metric(title, y_label, train_data, test_data):\n",
        "    epochs = list(range(1, 101))\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Adding Train Line with Markers\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=epochs, y=train_data, mode='lines+markers',\n",
        "        name='Train',\n",
        "        line=dict(color='RoyalBlue', width=2),\n",
        "        marker=dict(color='RoyalBlue', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "    ))\n",
        "\n",
        "    # Adding Test Line with Markers\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=epochs, y=test_data, mode='lines+markers',\n",
        "        name='Test',\n",
        "        line=dict(color='Crimson', width=2, dash='dot'),\n",
        "        marker=dict(color='Crimson', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "    ))\n",
        "\n",
        "    # Update Layout\n",
        "    fig.update_layout(\n",
        "        title={'text': title, 'y':0.9, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},\n",
        "        xaxis_title='Epoch',\n",
        "        yaxis_title=y_label,\n",
        "        legend=dict(x=0.1, y=1.1, orientation='h'),\n",
        "        font=dict(family=\"Helvetica, Arial, sans-serif\", size=12, color=\"black\"),\n",
        "        plot_bgcolor='white',\n",
        "        margin=dict(l=40, r=40, t=40, b=30)\n",
        "    )\n",
        "\n",
        "    # Gridlines and Axes styles\n",
        "    fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "    fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "\n",
        "    fig.show()"
      ],
      "id": "ae636153",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example usage\n",
        "plot_metric(\"Training and Testing Loss\", \"Loss\", train_losses, test_losses)\n",
        "plot_metric(\"Training and Testing Accuracy\", \"Accuracy (%)\", train_accuracies, test_accuracies)\n",
        "plot_metric(\"Training and Testing Discrimination\", \"Discrimination\", train_discriminations, test_discriminations)\n",
        "plot_metric(\"Training and Testing Fairness\", \"Fairness\", train_fairness, test_fairness)"
      ],
      "id": "5ea7c76e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BCE Loss Fn\n"
      ],
      "id": "9787239f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the model\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Custom loss function|\n",
        "def discrimination_loss(output, target, sensitive_features, lambda_val=100, k=2):\n",
        "    criterion = nn.BCELoss()\n",
        "    standard_loss = criterion(output, target)\n",
        "\n",
        "    mask_unpriv = (sensitive_features == 0)\n",
        "    mask_priv = (sensitive_features == 1)\n",
        "    #discrimination=torch.abs(prob_priv)\n",
        "    prob_unpriv = torch.mean(output[mask_unpriv])\n",
        "    prob_priv = torch.mean(output[mask_priv])\n",
        "    discrimination = lambda_val*(prob_priv - prob_unpriv) ** k\n",
        "\n",
        "# Handle cases where one group might be missing\n",
        "    #discrimination=torch.abs(prob_priv)\n",
        " \n",
        "    loss_val=standard_loss\n",
        "\n",
        "    return loss_val,discrimination.item() \n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    predicted_classes = (predictions >= 0.5).float()\n",
        "    return (predicted_classes == targets).float().mean()\n",
        "\n",
        "\n",
        "data = torch.tensor(X_train_scaled).float()\n",
        "targets = torch.tensor(y_train).float().unsqueeze(1)\n",
        "\n",
        "# Correctly preparing the sensitive features\n",
        "threshold = 0.5  # Adjust the threshold according to your specific case\n",
        "sensitive_features = torch.tensor((data[:, 1].numpy() > threshold).astype(float)).float()\n",
        "features = torch.cat((data[:, :1], data[:, 2:]), dim=1)\n",
        "\n",
        "# Assuming similar preparation for test data\n",
        "test_data = torch.tensor(X_test_scaled).float()\n",
        "test_targets = torch.tensor(y_test).float().unsqueeze(1)\n",
        "test_sensitive_features = torch.tensor((test_data[:, 1].numpy() > threshold).astype(float)).float()\n",
        "test_features = torch.cat((test_data[:, :1], test_data[:, 2:]), dim=1)\n",
        "\n",
        "model = BinaryClassifier(features.shape[1])\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "train_losses1, train_accuracies1, train_discriminations1,train_fairness1 = [], [], [],[]\n",
        "test_losses1, test_accuracies1, test_discriminations1,test_fairness1 = [], [], [],[]\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(features)\n",
        "    loss, discrimination = discrimination_loss(outputs, targets.squeeze(), sensitive_features)\n",
        "    train_accuracy = calculate_accuracy(outputs, targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Evaluation on test data\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(test_features)\n",
        "        test_loss,test_discrimination = discrimination_loss(test_outputs, test_targets.squeeze(), test_sensitive_features)\n",
        "        test_accuracy = calculate_accuracy(test_outputs, test_targets.squeeze())\n",
        "    \n",
        "    print(f'Epoch {epoch+1}, Train Loss: {loss.item()}, Train Acc: {train_accuracy.item()*100:.2f}%, Train Discrimination: {discrimination} '\n",
        "          f'Test Loss: {test_loss.item()}, Test Acc: {test_accuracy.item()*100:.2f}%,Test Discrimination: {test_discrimination}')\n",
        "    train_losses1.append(loss.item())\n",
        "    train_accuracies1.append(train_accuracy.item() * 100)\n",
        "    train_discriminations1.append(discrimination)\n",
        "    fairness=1-discrimination\n",
        "    train_fairness1.append(fairness)\n",
        "    test_fairness1.append(fairness)\n",
        "    test_losses1.append(test_loss.item())\n",
        "    test_accuracies1.append(test_accuracy.item() * 100)\n",
        "    test_discriminations1.append(test_discrimination)\n",
        "    model.train()"
      ],
      "id": "70649115",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "def plot_metric(title, y_label, train_data, test_data, x_title = \"Epoch\", epoch_blue = \"train\", epoch_red = \"Test\"):\n",
        "    epochs = list(range(1, 101))\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Adding Train Line with Markers\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=epochs, y=train_data, mode='lines+markers',\n",
        "        name=epoch_blue,\n",
        "        line=dict(color='RoyalBlue', width=2),\n",
        "        marker=dict(color='RoyalBlue', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "    ))\n",
        "\n",
        "    # Adding Test Line with Markers\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=epochs, y=test_data, mode='lines+markers',\n",
        "        name=epoch_red,\n",
        "        line=dict(color='Crimson', width=2, dash='dot'),\n",
        "        marker=dict(color='Crimson', size=6, line=dict(width=1, color='DarkSlateGrey'))\n",
        "    ))\n",
        "\n",
        "    # Update Layout\n",
        "    fig.update_layout(\n",
        "        title={'text': title, 'y':0.9, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},\n",
        "        xaxis_title=x_title,\n",
        "        yaxis_title=y_label,\n",
        "        legend=dict(x=0.1, y=1.1, orientation='h'),\n",
        "        font=dict(family=\"Helvetica, Arial, sans-serif\", size=12, color=\"black\"),\n",
        "        plot_bgcolor='white',\n",
        "        margin=dict(l=40, r=40, t=40, b=30)\n",
        "    )\n",
        "\n",
        "    # Gridlines and Axes styles\n",
        "    fig.update_xaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "    fig.update_yaxes(showline=True, linewidth=2, linecolor='black', gridcolor='LightGrey')\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "# Example usage\n",
        "plot_metric(\"Training and Testing Loss\", \"Loss\", train_losses1, test_losses1)\n",
        "plot_metric(\"Training and Testing Accuracy\", \"Accuracy (%)\", train_accuracies1, test_accuracies1)\n",
        "plot_metric(\"Training and Testing Discrimination\", \"Discrimination\", train_discriminations1, test_discriminations1)\n",
        "plot_metric(\"Training and Testing Fairness\", \"Fairness\", train_fairness1, test_fairness1)"
      ],
      "id": "e598ba84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_metric(\"DISPARITY IN FAIRNESS\", \"FAIRNESS\", test_fairness, test_fairness1, \"EPOCH\", \"WITH DISCRIMINATION FUNCTION\", \"BCE\")"
      ],
      "id": "e2dda5f0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\srinivas\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}